import os
import logging
import datetime
from typing import Dict, List

# Base paths
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")

# Ensure data directories exist
CHATS_DIR = os.path.join(DATA_DIR, "chats")
USERS_DIR = os.path.join(DATA_DIR, "users")
PERSONAS_DIR = os.path.join(DATA_DIR, "personas")

for directory in [CHATS_DIR, USERS_DIR, PERSONAS_DIR]:
    os.makedirs(directory, exist_ok=True)

# Ollama configuration
OLLAMA_CONFIG = {
    "default_model": "deepseek-r1:7b",
    "available_models": ["deepseek-r1:7b"],  # Can be expanded later
    "ollama_host": "http://localhost:11434",  # For local development
    # "ollama_host": "SERVER_URL_PLACEHOLDER",  # For production deployment
}

# UI Configuration
UI_CONFIG = {
    "page_title": "æ™“æ˜ŠåŠ©æ‰‹",
    "page_icon": "ğŸ¤–",
    "layout": "wide",
    "initial_sidebar_state": "expanded"
}

# Default personas dictionary
PERSONAS_DATA = {
    "default": {
        "name": "é€šç”¨åŠ©æ‰‹",
        "description": "ä¸€ä¸ªé€šç”¨çš„AIåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”å„ç§é—®é¢˜ã€‚",
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚",
    },
    "medical": {
        "name": "åŒ»ç–—åŠ©æ‰‹",
        "description": "ä¸“æ³¨äºåŒ»ç–—å¥åº·é¢†åŸŸçš„AIåŠ©æ‰‹ã€‚",
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªåŒ»ç–—é¢†åŸŸçš„AIåŠ©æ‰‹ï¼Œæä¾›å¥åº·ç›¸å…³çš„ä¿¡æ¯ã€‚æ³¨æ„ï¼šä½ ä¸åº”è¯¥æä¾›åŒ»ç–—è¯Šæ–­æˆ–æ²»ç–—å»ºè®®ï¼Œä»…æä¾›ä¸€èˆ¬æ€§çš„åŒ»ç–—ä¿¡æ¯ã€‚",
    },
    "legal": {
        "name": "æ³•å¾‹åŠ©æ‰‹",
        "description": "ä¸“æ³¨äºæ³•å¾‹é¢†åŸŸçš„AIåŠ©æ‰‹ã€‚",
        "system_prompt": "ä½ æ˜¯ä¸€ä¸ªæ³•å¾‹é¢†åŸŸçš„AIåŠ©æ‰‹ï¼Œæä¾›æ³•å¾‹ç›¸å…³çš„ä¿¡æ¯ã€‚æ³¨æ„ï¼šä½ ä¸åº”è¯¥æä¾›å…·ä½“çš„æ³•å¾‹å»ºè®®ï¼Œä»…æä¾›ä¸€èˆ¬æ€§çš„æ³•å¾‹ä¿¡æ¯ã€‚",
    }
}

def get_default_personas():
    """è¿”å›é»˜è®¤è§’è‰²åˆ—è¡¨ï¼Œé¿å…å¾ªç¯å¯¼å…¥"""
    from app.models.persona import Persona
    
    return [
        Persona(
            persona_id=persona_id,
            name=data["name"],
            description=data["description"],
            system_prompt=data["system_prompt"],
            created_at=datetime.datetime.now().isoformat()
        )
        for persona_id, data in PERSONAS_DATA.items()
    ]

# LLM options
THINKING_MODE_OPTIONS = {
    "normal": {
        "temperature": 0.7,
        "top_p": 0.9,
        "top_k": 40,
        "num_predict": 1024,
    },
    "deep": {
        "temperature": 0.7,
        "top_p": 0.9,
        "top_k": 40,
        "num_predict": 2048,  # Generate longer responses
    }
}

# Logging configuration
def setup_logging():
    """Configure application logging"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler(os.path.join(BASE_DIR, "app.log"))
        ]
    )
    return logging.getLogger("xiaohaochat") 